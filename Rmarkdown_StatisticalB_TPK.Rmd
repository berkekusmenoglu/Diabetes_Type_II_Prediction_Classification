---
title: "Statistical Learning B: Final Project"
subtitle: "Diabetes Type II Prediction and Classification"
author: "Berke Furkan Kusmenoglu (2041496), Ivan Dragomirov Padezhki (2041499), Elisa Tremolada (2013013)"
date: "17/06/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries

Import necessary libraries for the analysis.

```{r, label= 'libraries', message = FALSE}
library(tidyverse)
library(MASS)
library(caret)
library(ggplot2)
library(corrplot)
library(ggcorrplot)
library(Hmisc)
library(corrplot)
library(RColorBrewer)
library(stats)
library(readr)
library(glmnet)
library(gridExtra) 
library(grid)
library(car)
library(ROCR)
library(pROC)

```

# 1 Dataset

## 1.1 Introduction

The data set chosen for the current project is related to a paper exploring the connection between lifestyle, family history and Type 2 diabetes in the Indian population. The related article is Tigga, N. P., & Garg, S. (2020). Prediction of Type 2 Diabetes using Machine Learning Classification Methods. Procedia Computer Science, 167, 706-716. DOI: <https://doi.org/10.1016/j.procs.2020.03.336>. The data set can be found at <https://www.kaggle.com/datasets/tigganeha4/diabetes-dataset-2019> and was first accessed on 30/05/2022.

## 1.2 Importing the data

```{r}
library(readr)
ds <- read_csv("https://raw.githubusercontent.com/ivanpadezhki/stat_learning_2/master/data/diabetes_dataset__2019.csv?token=GHSAT0AAAAAABTXCTNAD4HUUN5MUAT2TSDEYU6D7XA")

```

## 1.3 Data preprocessing

From a preliminary inspection we find three variables ('BPLevel', 'Pdiabetes', 'Diabetes') have received different codes for the same levels (e.g. some are lowercase, others start with a capital letter).

Moreover, we report below all levels for each variables, which will be useful to transform them into binary variables.

```{r}
for(i in 1:ncol(ds)) {       
  print(lapply(ds[i], unique))
}
```

### 1.3.1 Normalization of value labels

```{r}
# Copy data into a new variable to retain original data frame
ds_fin <- ds

# Fixing variable name Pregancies
ds_fin <- ds_fin %>% rename(Pregnancies=Pregancies)

#Fixing the variable Pdiabetes 
ds_fin$Pdiabetes[ds_fin$Pdiabetes == ''] <- NA
ds_fin$Pdiabetes[ds_fin$Pdiabetes == ' no'] <- 'no'
ds_fin$Pdiabetes[ds_fin$Pdiabetes == '0'] <- 'no'

#Fixing the variable Diabetic
ds_fin$Diabetic[ds_fin$Diabetic == ' no'] <- 'no'
ds_fin$Diabetic[ds_fin$Diabetic == ''] <- NA

#Fixing the variable BPLevel
ds_fin$BPLevel[ds_fin$BPLevel == 'High'] <- 'high'
ds_fin$BPLevel[ds_fin$BPLevel == 'Low'] <- 'low'
ds_fin$BPLevel[ds_fin$BPLevel == 'normal '] <- 'normal'

# Fixing the variable RegularMedicine
ds_fin$RegularMedicine[ds_fin$RegularMedicine == 'o'] <- 'no'
```

### 1.3.2 Identifying Missing Values

The whole data set contains 48 missing values; in light of the relatively large number of observations (952), the rows containing NA values will be removed from the data set prior to analysis.

```{r}
sum(is.na(ds_fin)==TRUE)

```

First, we investigate the rows with missing values to identify potential patterns.

In fact, most of the missing values are in the variable 'Pregnancies'. The research paper provides no explanation for the high number of NAs in this variable. Furthermore, the NAs are present for both female and male individuals, so there is not a reason to suspect a pattern.

Thus, the rows containing missing values are removed from the data set.

```{r}
ds_fin[rowSums(is.na(ds_fin)) > 0, ]
ds_fin <- na.omit(ds_fin)
```

#### 1.3.2.1 Identifying weird observations

A later check of the data led to the discovery of 12 individuals coded as "Male" who at the same time have a value larger than 0 for the variable Pregnancies. Since the chance of having 12 transgender men who have had 1 or more pregnancies in our data set are rather low, these observations are excluded from further analyses.

```{r}
preg_male <- subset(ds_fin, Gender == 'Male' & Pregnancies != 0)
# Take a closer look at the observations to potentially identify if it is a data entry mistake
preg_male
# exclude individuals from data set
ds_fin <- ds_fin[!(ds_fin$Gender == 'Male' & ds_fin$Pregnancies != 0),]
```

### 1.3.3 Turning categorical variables into dummy variables

Binary variables with yes/no as levels are coded as 1 versus 0.

For variables with more than two levels, the lowest level is taken as baseline and the rest are contrasted with it.

The reason for this choice of dummy coding is that none of the categorical variables are nominally scaled, rather they are ordinal variables without measurable distances between different levels. Therefore, coding them as numerical variables is not appropriate.

The end result is a data set containing 26 predictor variables.

```{r}

# Keep ds_pre for creating labeled plots easier later
ds_pre <- ds_fin


# Variable AGE - has 4 levels, cast into 3 dummy variables with baseline <40 yo
ds_fin$Age40_49 <- ifelse(ds_fin$Age == "40-49", 1, 0)
ds_fin$Age50_59 <- ifelse(ds_fin$Age == "50-59", 1, 0)
ds_fin$Age_60 <- ifelse(ds_fin$Age == "60 or older", 1, 0)
ds_fin$Age <- NULL

# Variable GENDER (has two levels: male/female)
ds_fin$Gender_M <- ifelse(ds_fin$Gender == "Male", 1, 0)
ds_fin$Gender <- NULL

# Variable FAMILY DIABETES - has two levels (yes/no)
ds_fin$Family_Diabetes <- ifelse(ds_fin$Family_Diabetes == "yes", 1, 0)

# Variable high blood pressure - has two levels (yes/no)
ds_fin$highBP <- ifelse(ds_fin$highBP == "yes", 1, 0)

# Variable Physically Active: has 4 levels: none/ less than 30 min/ more than 30 min/ more than 1 hr
# cast into three dummy variables with "none" as baseline
ds_fin$PhysLow <- ifelse(ds_fin$PhysicallyActive == "less than half an hr", 1, 0)
ds_fin$PhysMid <- ifelse(ds_fin$PhysicallyActive == "more than half an hr", 1, 0)
ds_fin$PhysHigh <- ifelse(ds_fin$PhysicallyActive == "one hr or more", 1, 0)
ds_fin$PhysicallyActive <- NULL 

#Vairable BMI: we know from the paper underlying the dataset that having a BMI>25 is considered an 
#important risk factor for developing diabetes. Hence, we turn BMI into a dummy variable,
# taking value=0 when the subject has BMI < 25 and value 1 when BMI >= 25. 

ds_fin$BMI <- ifelse(ds_fin$BMI >= 25, 1, 0)

# Variable Smoking - has two levels (yes/no)
ds_fin$Smoking <- ifelse(ds_fin$Smoking == "yes", 1, 0)

# Variable Alcohol - has two levels (yes/no)
ds_fin$Alcohol <- ifelse(ds_fin$Alcohol == "yes", 1, 0)

# Variable Regular Medicine - has two levels yes/no
ds_fin$RegularMedicine <- ifelse(ds_fin$RegularMedicine == "yes", 1, 0)

# Variable Junk Food - contains 4 levels: occasionally/ often/ very often/ always
ds_fin$JunkOften <- ifelse(ds_fin$JunkFood == "often", 1, 0)
ds_fin$JunkVeryOften <- ifelse(ds_fin$JunkFood == "very often", 1, 0)
ds_fin$JunkAlways <- ifelse(ds_fin$JunkFood == "always", 1, 0)
ds_fin$JunkFood <- NULL

# Variable Stress has 4 levels: not at all/ sometimes/ very often/ always
ds_fin$StressSometimes <- ifelse(ds_fin$Stress == "sometimes", 1, 0)
ds_fin$StressOften <- ifelse(ds_fin$Stress == "very often", 1, 0)
ds_fin$StressAlways <- ifelse(ds_fin$Stress == "always", 1, 0)
ds_fin$Stress <- NULL

# Variable BPLevel - similar to highBP, but has three levels (low/normal/high)
ds_fin$BPNormal <- ifelse(ds_fin$BPLevel == "normal", 1, 0)
ds_fin$BPHigh <- ifelse(ds_fin$BPLevel == "high", 1, 0)
ds_fin$BPLevel <- NULL

# Variable PDiabetes: Gestational Diabetes (during pregnancy) - contains yes/no
ds_fin$Pdiabetes <- ifelse(ds_fin$Pdiabetes == "yes", 1, 0)

# Variable Urination Frequency with two levels - not much/ quite often
ds_fin$UriationFreq <- ifelse(ds_fin$UriationFreq == "quite often", 1, 0)

# Outcome Variable Diabetic with two levels - yes/ no
ds_fin$Diabetic <- ifelse(ds_fin$Diabetic == "yes", 1, 0)
```

Finally, we perform a check of the transformation.

```{r}
# this for-loop returns an output only if a certain variable is not numeric

for(i in 1:ncol(ds_fin)) {       
  if (lapply(ds_fin[1], class) != 'numeric'){
    print(lapply(ds_fin[i], class))
  }
}
```

### 1.3.4 Checking numerical variables

We investigate numerical variables BMI, Sleep and SoundSleep means and standard deviations ['BMI': \mu = 25.764, std = 5.403; 'Sleep' (\mu = 6.957, std = 1.273); 'SoundSleep' (\mu = 5.547, std = 1.871)]. However, we will use logistic regression, so we do not need to standardize these variables.

```{r}
mean(ds_fin$BMI)
sd(ds_fin$BMI)

mean(ds_fin$Sleep)
sd(ds_fin$Sleep)

mean(ds_fin$SoundSleep)
sd(ds_fin$SoundSleep)

```

## 1.4 Exploratory Data Analysis: Graphical EDA

An important question is whether the outcome variable is balanced. In the current data set, our class of interest (diabetic subjects) has less than half the observations with respect to non-diabetic subjects.

Since this is not a large imbalance, the analyses will be performed without any data over/undersampling.

However, the development of this problem will be monitored throughout the analysis, especially in the diagnosis of the model.

```{r}
table(ds_fin$Diabetic)
```

In this section we produce some plots, with the intention of better understanding the distribution of the predictor variables in our dataset - both with respect to each other and with respect to the output variable "Diabetic".

### 1.4.1 Numerical Variables

```{r}
# histogram of numerical variables
hist_bmi <- ggplot(ds_pre, aes(x=BMI)) + 
  geom_histogram(color="black", fill="white", binwidth = 0.9) + labs(x = "BMI")
hist_sleep <- ggplot(ds_fin, aes(x=Sleep)) + 
  geom_histogram(color="black", fill="white", binwidth = 0.9) + labs(x = "Hours of Sleep")
hist_soundsl <- ggplot(ds_fin, aes(x=SoundSleep)) + 
  geom_histogram(color="black", fill="white", binwidth = 0.9) + labs(x = "Hours of Sound Sleep")
hist_preg <- ggplot(ds_fin[ds_fin$Gender_M!=1,], aes(x=Pregnancies)) + 
  geom_histogram(color="black", fill="white", binwidth = 0.9) + labs(x = "Pregnancies (Women)")
grid.arrange(hist_bmi, hist_sleep, hist_soundsl, hist_preg, ncol = 4, top=textGrob("Histograms of Numerical Variables"))
```

Furthermore, the relationship of the numerical variables with the outcome variable is explored. There doesn't seem to be a reason to expect large differences in the outcome variable based on the three numerical variables studied below.

```{r}
box_bmi <- ggplot(ds_pre, aes(x=Diabetic, y=BMI)) + 
    geom_boxplot() +
  geom_jitter(alpha = 0.5, width = 0.2, height = 0.2, color = "tomato")
box_sleep <- ggplot(ds_pre, aes(x=Diabetic, y=Sleep)) + 
    geom_boxplot() + 
  geom_jitter(alpha = 0.5, width = 0.2, height = 0.2, color = "tomato")
box_ssleep <- ggplot(ds_pre, aes(x=Diabetic, y=SoundSleep)) + 
    geom_boxplot() +
  geom_jitter(alpha = 0.5, width = 0.2, height = 0.2, color = "tomato")
grid.arrange(box_bmi, box_sleep, box_ssleep, ncol = 3, top=textGrob("Boxplots of Numerical Variables"))
```

Additionally, the relationship between Sleep and Sound Sleep is evaluated. There seems to be reason to suspect possible interaction between the two variables, potentially due to correlation. For this reason, in a future model we will consider excluding one of the two variables.

```{r, message=FALSE}
ggplot(ds_pre, aes(x=Sleep, y=SoundSleep, shape = Diabetic, color = Diabetic)) + geom_point() +
  geom_smooth(method=lm, level=0.95) + 
  labs(y = "Hours of Sound Sleep", title = "Scatter Plot of Sleep and Sound Sleep") +
  # move the title text to the middle
  theme(plot.title=element_text(hjust=0.5))
```

### 1.4.2 Categorical variables

Next, we inspect the categorical variables and their relationships.

```{r}
get_legend<-function(myggplot){
  tmp <- ggplot_gtable(ggplot_build(myggplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}
```

```{r}
# build plots
bar_age <- ggplot(ds_pre, aes(x=reorder(Age, Age, function(x)-length(x)))) + 
   geom_bar(fill='red') +  labs(x='Age') + 
  scale_x_discrete(labels=c("less than 40" = "< 40", "40-49" = "40-49",
                              "50-59" = "40-49", "60 or older" = ">60"))
bar_gender <- ggplot(ds, aes(x=reorder(Gender, Gender, function(x)-length(x)))) + 
   geom_bar(fill='red') +  labs(x='Gender')
bar_familyd <- ggplot(ds, aes(x=reorder(Family_Diabetes, Family_Diabetes, function(x)-length(x)))) + 
   geom_bar(fill='red') +  labs(x='Family Diabetes')

bar_smoking <- ggplot(data = ds_pre, aes(x = Smoking)) +
    geom_bar() + theme(legend.position = "none")
bar_alc <- ggplot(data = ds_pre, aes(x = Alcohol)) +
    geom_bar() + theme(legend.position = "none")
bar_med <- ggplot(data = ds_pre, aes(x = RegularMedicine)) +
  geom_bar() + theme(legend.position="none")
# reorder Stress levels
ds_pre$Stress <- factor(ds_pre$Stress,levels = c("not at all", "sometimes", "very often", "always"))
# plot Stress
bar_stress <- ggplot(data = ds_pre, aes(x = Stress)) +
  geom_bar() + 
  theme(legend.position = "none", axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  scale_x_discrete(labels=c("not at all" = "none.", "sometimes" = "somet.",
                              "very often" = "v. often", "always" = "alw."))

# reorder levels of JunkFood
ds_pre$JunkFood <- factor(ds_pre$JunkFood,levels = c("occasionally", "often", "very often", "always"))
bar_junk <- ggplot(data = ds_pre, aes(x = JunkFood)) +
    geom_bar() + theme(legend.position = "none", axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
   scale_x_discrete(labels=c("occasionally" = "occas.", "often" = "often",
                              "very often" = "v. often", "always" = "alw."))

# reorder levels of Physical Activity
ds_pre$PhysicallyActive <- factor(ds_pre$PhysicallyActive,levels = c("none", "less than half an hr", "more than half an hr", "one hr or more"))
# plot physical activity 
bar_act <- ggplot(data = ds_pre, aes(x = PhysicallyActive)) +
    geom_bar() + theme(legend.position = "none", axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
  scale_x_discrete(labels=c("none" = "none", "less than half an hr" = "<30 m",
                              "more than half an hr" = ">30 m", "one hr or more" = ">1 hr"))

bar_urin <- ggplot(data = ds_pre, aes(x = UriationFreq)) +
    geom_bar() + theme(legend.position = "none")
# reorder BPlevel to be low, normal, high
ds_pre$BPLevel <- factor(ds_pre$BPLevel,levels = c("low", "normal", "high"))
# plot BPLevel 
bar_bplev <- ggplot(data = ds_pre, aes(x = BPLevel)) +
    geom_bar() + theme(legend.position="none")
bar_highbp <- ggplot(data = ds_pre, aes(x = highBP)) +
  geom_bar() + theme(legend.position="none")

# Plot first group 
grid.arrange(bar_age, bar_gender, bar_familyd, ncol = 3, top=textGrob("Barplots of First Group of Categorical Variables"))
# plot second group
grid.arrange(bar_smoking, bar_alc, bar_med, bar_urin, bar_bplev, bar_highbp, ncol = 3, top=textGrob("Bar Plots of Categorical Variables"))
# plot third group
grid.arrange(bar_junk, bar_act, bar_stress, ncol = 3, top=textGrob("Bar Plots of Categorical Variables"))

```

Create proportional plots for relevant variables and their relationship with the outcome variable.

```{r}
# Variable Age
# reorder levels
ds_pre$Age <- factor(ds_pre$Age,levels = c("less than 40", "40-49", "50-59", "60 or older"))
prop_age <- ggplot(data = ds_pre, aes(x = Age, fill = Diabetic)) +
  geom_bar(position = 'fill') + 
  theme(legend.position = 'none') +
  labs(y = 'Proportion') + 
  scale_x_discrete(labels=c("less than 40" = "< 40", "40-49" = "40-49",
                              "50-59" = "40-49", "60 or older" = ">60"))
# Gender
prop_gender <- ggplot(data = ds_pre, aes(x = Gender, fill = Diabetic)) +
  geom_bar(position = 'fill') + 
  theme(legend.position = 'none') +
  labs(y = 'Proportion')
# Family Diabetes
prop_famdiab <- ggplot(data = ds_pre, aes(x = Family_Diabetes, fill = Diabetic)) +
  geom_bar(position = 'fill') + 
  theme(legend.position = 'none') +
  labs(y = 'Proportion')
# Junk Food
prop_junk <- ggplot(data = ds_pre, aes(x = JunkFood, fill = Diabetic)) +
  geom_bar(position = 'fill') + 
  theme(legend.position = "none", axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
  labs(y = "Proportion") +
  scale_x_discrete(labels=c("occasionally" = "occas.", "often" = "often",
                              "very often" = "v. often", "always" = "alw."))
# Alcohol
prop_alc <- ggplot(data = ds_pre, aes(x = Alcohol, fill = Diabetic)) +
  geom_bar(position = 'fill') + theme(legend.position = "none") + labs(y = "Proportion")
# Physical Activity
prop_act <- ggplot(data = ds_pre, aes(x = PhysicallyActive, fill = Diabetic)) +
  geom_bar(position = 'fill') + 
  theme(legend.position = "none", axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
  labs(y = "Proportion") + 
  scale_x_discrete(labels=c("none" = "none", "less than half an hr" = "<30 m",
                              "more than half an hr" = ">30 m", "one hr or more" = ">1 hr"))
# Regular Medicine
prop_med <- ggplot(data = ds_pre, aes(x = RegularMedicine, fill = Diabetic)) +
  geom_bar(position = 'fill') + theme(legend.position="none") + labs(y = "Proportion")
# Smoking
prop_smoke <- ggplot(data = ds_pre, aes(x = Smoking, fill = Diabetic)) +
  geom_bar(position = 'fill') + theme(legend.position = "none") + labs(y = "Proportion")
# Stress
prop_stress <- ggplot(data = ds_pre, aes(x = Stress, fill = Diabetic)) +
  geom_bar(position = 'fill') + 
  theme(legend.position = "none", axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
  labs(y = "Proportion") +
  scale_x_discrete(labels=c("not at all" = "none.", "sometimes" = "somet.",
                              "very often" = "v. often", "always" = "alw."))
# Blood Pressure Level
prop_bplev <- ggplot(data = ds_pre, aes(x = BPLevel, fill = Diabetic)) +
    geom_bar(position = 'fill') + theme(legend.position="none")
# High Blood pressure
prop_highbp <- ggplot(data = ds_pre, aes(x = highBP, fill = Diabetic)) +
  geom_bar(position = 'fill') + theme(legend.position="none")
# Urination Frequency
prop_urin <- ggplot(data = ds_pre, aes(x = UriationFreq, fill = Diabetic)) +
    geom_bar(position = 'fill')
# get legend
legend <- get_legend(prop_urin)
# delete legend from past plot
prop_urin <- prop_urin + theme(legend.position="none")

# Create graph with multiple plots
grid.arrange(prop_age, prop_gender, prop_famdiab, prop_med, legend, ncol = 3, top=textGrob("Bar plots of categorical Variables"))
grid.arrange(prop_junk, prop_act, prop_stress, prop_smoke, prop_alc, prop_act, ncol = 3, top=textGrob("Bar plots of categorical Variables"))
grid.arrange(prop_bplev, prop_highbp, prop_urin, legend, ncol = 3, top=textGrob("Bar plots of categorical Variables"))
```

### 1.4.3 Further exploration

Then, we take a look at some relationships between categorical and numerical variables

```{r}
gender_f <- ds_pre[ds_pre$Gender=='Female',]
ggplot(gender_f, aes(x=Diabetic, y=Pregnancies, fill = Pdiabetes)) + 
  geom_boxplot() + 
  geom_jitter(alpha = 0.5, width = 0.2, height = 0.2, color = "tomato") + 
  labs(x = "Diabetes", y = "Pregnancies", title = "Diabetes by Gestational Diabetes and Number of Pregnancies")+
  # move the title text to the middle
  theme(plot.title=element_text(hjust=0.5))
```

```{r}

box_alc.bmi <- ggplot(ds_pre, aes(x=Alcohol, y=BMI, fill = Diabetic)) + 
    geom_boxplot() + labs(title = "BMI by Alcohol Consumption and Diabetes")
box_age.bmi <- ggplot(ds_pre, aes(x=Age, y=BMI, fill = Diabetic)) + 
    geom_boxplot() + labs(title = "BMI by Age and Diabetes") + 
  scale_x_discrete(labels=c("less than 40" = "< 40", "40-49" = "40-49",
                              "50-59" = "40-49", "60 or older" = ">60"))
box_gender.bmi <- ggplot(ds_pre, aes(x=Gender, y=BMI, fill = Diabetic)) + 
    geom_boxplot() + labs(title = "BMI by Gender and Diabetes")
box_smoke.bmi <- ggplot(ds_pre, aes(x=Smoking, y=BMI, fill = Diabetic)) + 
    geom_boxplot() + labs(title = "BMI by Smoking and Diabetes")
box_fam.bmi <- ggplot(ds_pre, aes(x=Family_Diabetes, y=BMI, fill = Diabetic)) + 
    geom_boxplot() + labs(title = "BMI by Family Diabetes and Diabetes")
box_highbp.bmi <- ggplot(ds_pre, aes(x=highBP, y=BMI, fill = Diabetic)) + 
    geom_boxplot() + labs(title = "BMI by High Blood Pressure and Diabetes")
box_med.bmi <- ggplot(ds_pre, aes(x=RegularMedicine, y=BMI, fill = Diabetic)) + 
    geom_boxplot() + labs(title = "BMI by Regular Medicine and Diabetes")
box_urin.bmi <- ggplot(ds_pre, aes(x=UriationFreq, y=BMI, fill = Diabetic)) + 
    geom_boxplot() + labs(title = "BMI by Urination Frequency and Diabetes")
box_pdiab.bmi <- ggplot(gender_f, aes(x=Pdiabetes, y=BMI, fill = Diabetic)) + 
    geom_boxplot() + labs(title = "BMI by Gestational Diabetes and Diabetes")

grid.arrange(box_age.bmi, box_gender.bmi, box_fam.bmi, 
             ncol = 3, top=textGrob("Box Plots of BMI and Categorical Variables"))
grid.arrange(box_med.bmi, box_alc.bmi, box_smoke.bmi,
             ncol = 3, top=textGrob("Box Plots of BMI and Categorical Variables"))
grid.arrange(box_highbp.bmi, box_urin.bmi, box_pdiab.bmi, 
             ncol = 3, top=textGrob("Box Plots of BMI and Categorical Variables"))

```

### 1.4.4 Correlation matrix

In order to assess which variables should be kept when modeling our data, we produce an overview of the correlation structure of all variables

```{r}
corr <- cor(ds_fin)

#prepare to drop duplicates    

corr[lower.tri(corr,diag=TRUE)] <- NA 

# Correlation matrix 

library(ggcorrplot)
model.matrix(~0+., data=ds_fin) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag = F, type="upper", lab=TRUE, lab_size=2)

```

For clarity, we also report a table of the variables with highest correlation coefficients (i.e. \> 0.5). These variables are all potential candidates for being "dropped" in the modeling phase, which will be developed in the next section.

```{r}
w <- which(abs(corr)>0.5 & row(corr)<col(corr), arr.ind = TRUE)
# reconstruct names from positions
high_cor <- matrix(colnames(corr)[w],ncol=2)
high_cor
```

# 2 Modeling

First of all, we perform a train-test split of the dataset, in order to be able to carry out model validation later.

```{r}
# Split the data into training and test set

set.seed(123)
training.samples <- ds_fin$Diabetic %>% 
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- ds_fin[training.samples, ]
test.data <- ds_fin[-training.samples, ]
```

## 2.1 Logistic Regression

Following the rationale of the paper from which the dataset is taken, we wish to create a model which is able to satisfy two objectives:

1)  Identify the lifestyle and family factors which increase / decrease the probability of developing Type 2 diabetes
2)  Classify, as correctly as possible, diabetic and non-diabetic subjects

We believe in this case it is important to choose an interpretable model, since this analysis is mainly aimed at preventing the insurgence of diabetes; while models such as KNN could reach better performance in the classification task, they would provide no indication of which factors "weigh" more in the development of this pathology.

Thus, we choose to carry out a logistic regression on the binary variable "Diabetic". The full model is run below.

```{r}
# Full model 
log_reg <- glm(Diabetic ~., data = train.data, family = binomial)
summary(log_reg)

#Saving the AIC for later use

AIC_full = 432.18
```

## 2.2 Model diagnostics

Now, we use this model for prediction in order to assess its classification accuracy.

We are particularly interested in how well the model is able to identify diabetic subjects; since these results will likely be used for identifying good prevention practices rather than as a diagnostic tool (and, even then, the diagnosis would have to be confirmed through clinical test), we are not particularly worried about identifying a patient as sick when she is not - while we do care about identifying all truly sick patients as sick.

Hence, we are interested in calculating the sensitivity and precision of our model, which are reported below.

```{r}
#Prediction and confusion matrix for full model (p=0.5)

dim(test.data)
log_prob <- predict(log_reg, test.data, type = 'response')
logistic_pred <- rep(0, dim(test.data)[1])
logistic_pred[log_prob>0.5] <- 1
full_confusion <- confusionMatrix(data=as.factor(logistic_pred), reference = as.factor(test.data$Diabetic), positive = '1')
full_confusion
```
Next, we visualize the ROC curve for this model in order to observe its performance. 

```{r}
full_prediction <- prediction(logistic_pred, test.data$Diabetic)

roc_curve_full <- performance(full_prediction, measure="tpr", x.measure = "fpr" )

auc <- performance(full_prediction, measure="auc")

auc <- auc@y.values[[1]]

auc <- as.character(round(auc, 3))

p <- plot(roc_curve_full, lwd = 2, main = "ROC curve - Full model")

full_auc = paste("AUC = ", auc)
text(0.5, 0.5, full_auc)


```

We are interested in finding out if a lower treshold for parameter p of the logistic regression classifier could help us improve sensitivity, which is now 0.7636. Thus, we first calculate the error rate among diabetic individuals, and compare it with a new error rate for a classifier with a much lower treshold (p=0.1). Indeed, the testing error rate goes from 2.36% for the model with p=0.5, to 0.04% for the model with p=0.1

```{r}
# (Testing) error rate among diabetic subjects with p=0.5 

table(logistic_pred, test.data$Diabetic)
FN = table(logistic_pred, test.data$Diabetic)[1,2]
TP = table(logistic_pred, test.data$Diabetic)[2,2]
err_05 = FN/(FN+TP)
err_05 #0.2363636

#Prediction and confusion matrix for full model (p=0.1)

dim(test.data)
log_prob <- predict(log_reg, test.data, type = 'response')
logistic_pred_01 <- rep(0, dim(test.data)[1])
logistic_pred_01[log_prob>0.1] <- 1
full_confusion_01 <- confusionMatrix(data=as.factor(logistic_pred_01), reference = as.factor(test.data$Diabetic), positive = '1')
full_confusion_01

# (Testing) error rate among diabetic subjects with p=0.1 

table(logistic_pred_01, test.data$Diabetic)
FN = table(logistic_pred_01, test.data$Diabetic)[1,2]
TP = table(logistic_pred_01, test.data$Diabetic)[2,2]
err_01 = FN/(FN+TP)
err_01 #0.03636364

```
Here, we plot the ROC curve for the model with p=0.1, for comparison. 

```{r}

full_prediction_01 <- prediction(logistic_pred_01, test.data$Diabetic)

roc_curve_full_01 <- performance(full_prediction_01, measure="tpr", x.measure = "fpr" )

auc <- performance(full_prediction_01, measure="auc")

auc <- auc@y.values[[1]]

auc <- round(auc, 3)

plot(roc_curve_full_01, main="ROC curve - Full Model (p=0.1)", lwd=2)

auc_best_full = paste("AUC = ", auc)

text(0.5, 0.5, full_auc)

```

## 2.3 Variable selection

### 2.3.1 VIF analysis and multicollinearity check

Now, we check multicollinearity by checking the VIF for all coefficients in the logistic regression.

```{r}
# Vector of VIF values 

all_vif <- vif(log_reg)
length(all_vif)

# Create bar chart to display VIF values 

barplot(all_vif, main = "VIF for all coefficients - FULL MODEL", horiz = FALSE, col = "orange", names.arg = c('Fam_d','h_bp','BMI','smoke','alc','sleep','Ssleep','regmed','preg','pdiab','ur','40-49','50-59','60ab','male','lowphy','midphy','highphy','junkof','junkvof','junkal','stress1','stress2','stress3','normbp','highbp'), ylim = c(0,30)) 

# Add a line to highlight severe correlation when VIF > 5 

abline(h = 5, lwd = 3, lty = 1)    

```

We can observe from the graph above that VIF is under the critical value of 5 for all coefficient except for the ones related to the variables "BPNormal" and "BPHigh", indicating that one of this variables shall be removed in order to avoid multicollinearity.

First, we produce a model without "BPNormal".

```{r}
# 1. Model without variables: "BPNormal"

log_reg1 <- glm(Diabetic ~. -BPNormal, data = train.data, family = binomial)
summary(log_reg1)

#Saving the AIC for later use

AIC_1 = 536.38 
```

Secondly, we produce a model without "BPHigh".

```{r}

# 2. Model without variables: "BPHigh"

log_reg2 <- glm(Diabetic ~. -BPHigh, data = train.data, family = binomial)
summary(log_reg2)

#Saving the AIC for later use

AIC_2 = 538.99 
```

Below, we confirm both through AIC analysis and through the VIF plot for all coefficients that, indeed, the variable BPNormal suffered from multicollinearity and shall be removed from the model. Once removed, all coefficients show VIFs under the critical value of 5.

```{r}
#Checking which variable dropped produced a lowering of the AIC 

AIC_full > AIC_1 #TRUE

AIC_full > AIC_2 #FALSE 

# Creating a new VIF plot for log_reg1 (without BPNormal) 

all_vif1 <- vif(log_reg1)
length(all_vif1)

# Create bar chart to display VIF values 

barplot(all_vif1, main = "VIF for all coeficients - MODEL WITHOUT BPNormal", horiz = FALSE, col = "orange", names.arg = c('Fam_d','h_bp','BMI','smoke','alc','sleep','Ssleep','regmed','preg','pdiab','ur','40-49','50-59','60ab','male','lowphy','midphy','highphy','junkof','junkvof','junkal','stress1','stress2','stress3','highbp'), ylim = c(0,30)) 

# Add a line to highlight severe correlation when VIF > 5 

abline(h = 5, lwd = 3, lty = 1)    

```

Now, we observe this new model's performance through VIF analysis, sensitivity and precision measures.

```{r}
#Prediction and confusion matrix for model identified through VIF analysis

log_prob_VIFmod  <- predict(log_reg1, test.data, type = 'response')
logistic_pred_VIFmod  <- rep(0, dim(test.data)[1])
logistic_pred_VIFmod [log_prob_VIFmod>0.5] <- 1
vif_confusion <- confusionMatrix(data=as.factor(logistic_pred_VIFmod), reference = as.factor(test.data$Diabetic), positive = '1')
vif_confusion
```

Now, we check for the best treshold of P in the case of the new model without BPNormal (log_reg1).

```{r}
VIFmod_prediction <- prediction(logistic_pred_VIFmod, test.data$Diabetic)

roc_curve_VIFmod <- performance(VIFmod_prediction, measure="tpr", x.measure = "fpr" )

auc <- performance(VIFmod_prediction, measure="auc")

auc <- auc@y.values[[1]]

auc <- as.character(round(auc, 3))

plot(roc_curve_VIFmod, main="ROC curve - Model modified through VIF analysis (p=0.5)", lwd=2)

full_auc = paste("AUC = ", auc)

text(0.5, 0.5, full_auc)


```
Here, we repeat the procedure as above in order to identify the suitable treshold for maximum sensitivity. The error rate among diabetic individuals, which is 2.36% for p=0.5, lowers to 0.36% for p=0.1, as before. 

```{r}
# (Testing) error rate among diabetic subjects with p=0.5 

table(logistic_pred_VIFmod, test.data$Diabetic)
FN = table(logistic_pred_VIFmod, test.data$Diabetic)[1,2]
TP = table(logistic_pred_VIFmod, test.data$Diabetic)[2,2]
err_05_VIF = FN/(FN+TP)
err_05_VIF #0.2363636

#Prediction and confusion matrix for full model (p=0.1)

dim(test.data)
log_prob <- predict(log_reg1, test.data, type = 'response')
logistic_pred_VIFmod_01 <- rep(0, dim(test.data)[1])
logistic_pred_VIFmod_01[log_prob>0.1] <- 1
VIF_confusion_01 <- confusionMatrix(data=as.factor(logistic_pred_VIFmod_01), reference = as.factor(test.data$Diabetic), positive = '1')
VIF_confusion_01

# (Testing) error rate among diabetic subjects with p=0.1 

table(logistic_pred_VIFmod_01, test.data$Diabetic)
FN = table(logistic_pred_VIFmod_01, test.data$Diabetic)[1,2]
TP = table(logistic_pred_VIFmod_01, test.data$Diabetic)[2,2]
err_01_VIF = FN/(FN+TP)
err_01_VIF #0.03636364

```
Here, we plot the ROC curve for the model with p=0.1, for comparison. 

```{r}

VIF_prediction_01 <- prediction(logistic_pred_VIFmod_01, test.data$Diabetic)

roc_curve_VIF_01 <- performance(VIF_prediction_01, measure="tpr", x.measure = "fpr" )

auc <- performance(VIF_prediction_01, measure="auc")

auc <- auc@y.values[[1]]

auc <- round(auc, 3)

plot(roc_curve_VIF_01, main="ROC curve - Model Model modified through VIF analysis (p=0.1)", lwd=2)

auc_best_VIFmod = paste("AUC = ", auc)

text(0.5, 0.5, full_auc)

```

### 2.3.2 Stepwise logistic regression

Even after observing the VIFs and dropping BPNormal, we still have 25 explanatory variables in our model, many of which are not significant. In order to explore the possibility of dropping other variables, we perform an automatic stepwise selection procedure.

```{r}
#Stepwise logistic

model <- glm(Diabetic ~., data = train.data, family = binomial)
summary(model)
step.model <- model %>% stepAIC(trace = FALSE)
summary(step.model)
```

Now, we save the model with best AIC.

```{r}
#Saving the model with best AIC 

best.aic <- step.model
summary(best.aic)

#Saving the AIC 
best_AIC = 426.4
```

Finally, we produce the confusion matrix and sensitivity + precision measure for the best AIC model in order to evaluate its performance. 

```{r}

#Prediction and confusion matrix for best AIC model 

log_prob_bestAIC <- predict(best.aic, test.data, type = 'response')
logistic_pred_bestAIC <- rep(0, dim(test.data)[1])
logistic_pred_bestAIC[log_prob_bestAIC>0.5] <- 1
aic_confusion <- confusionMatrix(data=as.factor(logistic_pred_bestAIC), reference = as.factor(test.data$Diabetic), positive = '1')
aic_confusion

```
Here we plot the ROC curve for this model. 

```{r}
best_aic_prediction <- prediction(logistic_pred_bestAIC, test.data$Diabetic)

roc_curve_best_Aic <- performance(best_aic_prediction, measure="tpr", x.measure = "fpr" )

auc <- performance(best_aic_prediction, measure="auc")

auc <- auc@y.values[[1]]

auc <- round(auc, 3)

plot(roc_curve_best_Aic, main="ROC curve - Model with best AIC (p=0.5)", lwd=2)

full_auc = paste("AUC = ", auc)

text(0.5, 0.5, full_auc)

```

Here, we repeat the procedure for finding the best treshold for sensitivity measure, as above. The testing error rate among diabetic individuals lowers from 2% to 0.04% when we move the treshold from p=0.5 to p=0.1, confirming previous results. 

```{r}
# (Testing) error rate among diabetic subjects with p=0.5 

table(logistic_pred_bestAIC, test.data$Diabetic)
FN = table(logistic_pred_bestAIC, test.data$Diabetic)[1,2]
TP = table(logistic_pred_bestAIC, test.data$Diabetic)[2,2]
err_05_bestAIC  = FN/(FN+TP)
err_05_bestAIC  #0.2

#Prediction and confusion matrix for full model (p=0.1)

log_prob <- predict(best.aic, test.data, type = 'response')
logistic_pred_bestAIC_01 <- rep(0, dim(test.data)[1])
logistic_pred_bestAIC_01[log_prob>0.1] <- 1
full_confusion_01 <- confusionMatrix(data=as.factor(logistic_pred_bestAIC_01), reference = as.factor(test.data$Diabetic), positive = '1')
full_confusion_01

# (Testing) error rate among diabetic subjects with p=0.1 

table(logistic_pred_bestAIC_01, test.data$Diabetic)
FN = table(logistic_pred_bestAIC_01, test.data$Diabetic)[1,2]
TP = table(logistic_pred_bestAIC_01, test.data$Diabetic)[2,2]
err_01_bestAIC = FN/(FN+TP)
err_01_bestAIC #0.03636364

```

Here, we plot the ROC curve of the model with best perfomance in terms of sensitivity. 

```{r}
best_aic_prediction_01 <- prediction(logistic_pred_bestAIC_01, test.data$Diabetic)

roc_curve_best_Aic_01 <- performance(best_aic_prediction_01, measure="tpr", x.measure = "fpr" )

auc <- performance(best_aic_prediction_01, measure="auc")

auc <- auc@y.values[[1]]

auc <- round(auc, 3)

plot(roc_curve_best_Aic_01, main="ROC curve - Model with best AIC (p=0.1)", lwd=2)

auc_best_bestAIC = paste("AUC = ", auc)

text(0.5, 0.5, full_auc)

```

### 2.3.3 Comparison of models

In order to check which is our best model, we visually contrast both new models with the full model predictions in order to select the model with best performance.

```{r}
# Among models with best sensitivity, which has the highest AUC? 

auc_best_full > auc_best_bestAIC #TRUE

auc_best_bestAIC > auc_best_VIFmod #FALSE 

auc_best_full > auc_best_VIFmod #FALSE 

auc_best_VIFmod > auc_best_bestAIC #TRUE

auc_best_VIFmod == auc_best_full #TRUE: the model identified through VIF analysis and the full model
                                 # have the same, and highest, AUC 

```


```{r}

plot(roc_curve_full_01, col='orange', main='ROC curves for best models (p=0.1)', lty=1, lwd=2)

plot(roc_curve_VIF_01, add=TRUE, col='green', lty=3, lwd=2)

plot(roc_curve_best_Aic_01, add=TRUE, col='blue', lty=2, lwd=2)

auc <- performance(VIF_prediction_01, measure="auc")

auc <- auc@y.values[[1]]

auc <- round(auc, 3)

best_auc = paste("best model AUC = ", auc)

text(0.3, 0.3, best_auc)


legend(0.5, 0.5, legend=c("Full model", "VIF modified model", "Best AIC model"),
       col=c("orange", "green", "blue"), lty=c(1,3,2))

```


